{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7l06KzTP3uA",
        "outputId": "232b3c7f-9897-4300-ea92-c7ddce82b1cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: hopsworks in /usr/local/lib/python3.11/dist-packages (4.2.2)\n",
            "Requirement already satisfied: pyhumps==1.6.1 in /usr/local/lib/python3.11/dist-packages (from hopsworks) (1.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from hopsworks) (2.32.3)\n",
            "Requirement already satisfied: furl in /usr/local/lib/python3.11/dist-packages (from hopsworks) (2.1.4)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.11/dist-packages (from hopsworks) (1.38.12)\n",
            "Requirement already satisfied: pandas<2.2.0 in /usr/local/lib/python3.11/dist-packages (from hopsworks) (2.1.4)\n",
            "Requirement already satisfied: pyjks in /usr/local/lib/python3.11/dist-packages (from hopsworks) (20.0.0)\n",
            "Requirement already satisfied: mock in /usr/local/lib/python3.11/dist-packages (from hopsworks) (5.2.0)\n",
            "Requirement already satisfied: avro==1.11.3 in /usr/local/lib/python3.11/dist-packages (from hopsworks) (1.11.3)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.11/dist-packages (from hopsworks) (2.0.29)\n",
            "Requirement already satisfied: PyMySQL[rsa] in /usr/local/lib/python3.11/dist-packages (from hopsworks) (1.1.1)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.11/dist-packages (from hopsworks) (5.3.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from hopsworks) (2025.3.2)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.11/dist-packages (from hopsworks) (1.3.4)\n",
            "Requirement already satisfied: hopsworks_aiomysql==0.2.1 in /usr/local/lib/python3.11/dist-packages (from hopsworks_aiomysql[sa]==0.2.1->hopsworks) (0.2.1)\n",
            "Requirement already satisfied: opensearch-py<=2.4.2,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from hopsworks) (2.4.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from hopsworks) (4.67.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.49.1 in /usr/local/lib/python3.11/dist-packages (from hopsworks) (1.71.0)\n",
            "Requirement already satisfied: protobuf<5.0.0,>=4.25.4 in /usr/local/lib/python3.11/dist-packages (from hopsworks) (4.25.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from hopsworks) (24.2)\n",
            "Requirement already satisfied: urllib3>=1.26.18 in /usr/local/lib/python3.11/dist-packages (from opensearch-py<=2.4.2,>=1.1.0->hopsworks) (2.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from opensearch-py<=2.4.2,>=1.1.0->hopsworks) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from opensearch-py<=2.4.2,>=1.1.0->hopsworks) (2.9.0.post0)\n",
            "Requirement already satisfied: certifi>=2022.12.07 in /usr/local/lib/python3.11/dist-packages (from opensearch-py<=2.4.2,>=1.1.0->hopsworks) (2025.4.26)\n",
            "Requirement already satisfied: numpy<2,>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas<2.2.0->hopsworks) (1.26.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.2.0->hopsworks) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.2.0->hopsworks) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->hopsworks) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->hopsworks) (3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy->hopsworks) (4.13.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy->hopsworks) (3.2.1)\n",
            "Requirement already satisfied: botocore<1.39.0,>=1.38.12 in /usr/local/lib/python3.11/dist-packages (from boto3->hopsworks) (1.38.12)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3->hopsworks) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.13.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from boto3->hopsworks) (0.12.0)\n",
            "Requirement already satisfied: orderedmultidict>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from furl->hopsworks) (1.0.1)\n",
            "Requirement already satisfied: javaobj-py3 in /usr/local/lib/python3.11/dist-packages (from pyjks->hopsworks) (0.4.4)\n",
            "Requirement already satisfied: pyasn1>=0.3.5 in /usr/local/lib/python3.11/dist-packages (from pyjks->hopsworks) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.11/dist-packages (from pyjks->hopsworks) (0.4.2)\n",
            "Requirement already satisfied: pycryptodomex in /usr/local/lib/python3.11/dist-packages (from pyjks->hopsworks) (3.22.0)\n",
            "Requirement already satisfied: twofish in /usr/local/lib/python3.11/dist-packages (from pyjks->hopsworks) (0.3.0)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.11/dist-packages (from PyMySQL[rsa]->hopsworks) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography->PyMySQL[rsa]->hopsworks) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography->PyMySQL[rsa]->hopsworks) (2.22)\n"
          ]
        }
      ],
      "source": [
        "# STEP 1: Install Hopsworks SDK\n",
        "!pip install hopsworks --upgrade\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install confluent-kafka --quiet\n"
      ],
      "metadata": {
        "id": "3df3lPTeVkrH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hopsworks[python] confluent-kafka --upgrade --quiet\n"
      ],
      "metadata": {
        "id": "pf1gV4E7aFEg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install system dependencies\n",
        "!apt-get install -y libomp-dev\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36eNECfraGky",
        "outputId": "e0eba540-bdf9-4216-f22e-ffb66f900c03"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libomp-dev is already the newest version (1:14.0-55~exp2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install conda (if not already installed)\n",
        "!pip install conda\n",
        "\n",
        "# Install LightGBM with conda\n",
        "!conda install -c conda-forge lightgbm --yes\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDwTRqfyaIUT",
        "outputId": "bbc4de2c-ae0c-4e84-f915-1235382668cd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Ignored the following yanked versions: 3.0.6, 3.5.0, 3.7.0, 3.17.0, 4.0.0, 4.0.1, 4.0.2, 4.0.3, 4.0.4, 4.0.5, 4.0.7, 4.0.8, 4.0.9, 4.1.2, 4.1.6, 4.2.6, 4.2.7, 4.3.13, 4.3.16\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement conda (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for conda\u001b[0m\u001b[31m\n",
            "\u001b[0m/bin/bash: line 1: conda: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies to compile LightGBM from source\n",
        "!apt-get install -y libomp-dev\n",
        "!pip install -U setuptools\n",
        "!pip install -U scikit-learn scipy matplotlib\n",
        "!pip install -U lightgbm --no-binary lightgbm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOscg_3PaKY7",
        "outputId": "e5a72488-c1f1-4a94-e821-0fd65c4b166e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libomp-dev is already the newest version (1:14.0-55~exp2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (80.3.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.15.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.3)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (4.5.0)\n",
            "Collecting lightgbm\n",
            "  Using cached lightgbm-4.6.0.tar.gz (1.7 MB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.15.3)\n",
            "Building wheels for collected packages: lightgbm\n",
            "  Building wheel for lightgbm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lightgbm: filename=lightgbm-4.6.0-py3-none-linux_x86_64.whl size=3243731 sha256=3cbe56c2b62a9445ae2c19bf6a1d71a4c9e714077ccec9be1aa762371484807e\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/da/90/bd694ce19848ae41071e6c926d1650e4581556bf5869a57fe0\n",
            "Successfully built lightgbm\n",
            "Installing collected packages: lightgbm\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 4.5.0\n",
            "    Uninstalling lightgbm-4.5.0:\n",
            "      Successfully uninstalled lightgbm-4.5.0\n",
            "Successfully installed lightgbm-4.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install a precompiled lightgbm wheel directly\n",
        "!pip install https://github.com/microsoft/LightGBM/releases/download/v3.3.0/lightgbm-3.3.0-py3-none-manylinux1_x86_64.whl\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0J6-38EaMtU",
        "outputId": "4a175112-496a-4cf1-a1b1-3c633dfa3dc4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lightgbm==3.3.0\n",
            "  Downloading https://github.com/microsoft/LightGBM/releases/download/v3.3.0/lightgbm-3.3.0-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from lightgbm==3.3.0) (0.45.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from lightgbm==3.3.0) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lightgbm==3.3.0) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn!=0.22.0 in /usr/local/lib/python3.11/dist-packages (from lightgbm==3.3.0) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn!=0.22.0->lightgbm==3.3.0) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn!=0.22.0->lightgbm==3.3.0) (3.6.0)\n",
            "Installing collected packages: lightgbm\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 4.6.0\n",
            "    Uninstalling lightgbm-4.6.0:\n",
            "      Successfully uninstalled lightgbm-4.6.0\n",
            "Successfully installed lightgbm-3.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required system packages for LightGBM\n",
        "!apt-get install -y libomp-dev\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9aVWeSaaOxX",
        "outputId": "b4ee76ba-579a-4fcc-b21f-b7f9647cf112"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libomp-dev is already the newest version (1:14.0-55~exp2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install lightgbm from source\n",
        "!pip install lightgbm --no-binary lightgbm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxJ6mf30aQh1",
        "outputId": "deb77557-2e20-4e87-c363-c21f4da9be16"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (3.3.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from lightgbm) (0.45.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn!=0.22.0 in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn!=0.22.0->lightgbm) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn!=0.22.0->lightgbm) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: install mlflow\n",
        "\n",
        "!pip install mlflow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qj2e6OjbeA6j",
        "outputId": "8ccc3e4e-9419-464e-cbf0-57ca59688163"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mlflow\n",
            "  Downloading mlflow-2.22.0-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting mlflow-skinny==2.22.0 (from mlflow)\n",
            "  Downloading mlflow_skinny-2.22.0-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.0)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.6)\n",
            "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
            "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting graphene<4 (from mlflow)\n",
            "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting gunicorn<24 (from mlflow)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.8)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.10.3)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.26.4)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.1.4)\n",
            "Requirement already satisfied: pyarrow<20,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (18.1.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.6.1)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.15.3)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.29)\n",
            "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (8.1.8)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (3.1.1)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.22.0->mlflow)\n",
            "  Downloading databricks_sdk-0.52.0-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting fastapi<1 (from mlflow-skinny==2.22.0->mlflow)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (3.1.44)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (8.7.0)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (1.16.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (1.16.0)\n",
            "Requirement already satisfied: packaging<25 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (24.2)\n",
            "Requirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (4.25.7)\n",
            "Requirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (2.11.4)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (2.32.3)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (4.13.2)\n",
            "Collecting uvicorn<1 (from mlflow-skinny==2.22.0->mlflow)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.1.3)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker<8,>=4.0.0->mlflow) (2.4.0)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (1.9.0)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2<4,>=2.11->mlflow) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (3.2.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.2.1)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (2.38.0)\n",
            "Collecting starlette<0.47.0,>=0.40.0 (from fastapi<1->mlflow-skinny==2.22.0->mlflow)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.22.0->mlflow) (4.0.12)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.22.0->mlflow) (3.21.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (1.2.18)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (80.3.1)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.37b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (0.37b0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.0->mlflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.0->mlflow) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.0->mlflow) (2025.4.26)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn<1->mlflow-skinny==2.22.0->mlflow) (0.16.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (1.17.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.22.0->mlflow) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (4.9.1)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.22.0->mlflow) (4.9.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.22.0->mlflow) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (0.6.1)\n",
            "Downloading mlflow-2.22.0-py3-none-any.whl (29.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m29.0/29.0 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-2.22.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_sdk-0.52.0-py3-none-any.whl (700 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m700.2/700.2 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uvicorn, gunicorn, graphql-core, starlette, graphql-relay, docker, alembic, graphene, fastapi, databricks-sdk, mlflow-skinny, mlflow\n",
            "Successfully installed alembic-1.15.2 databricks-sdk-0.52.0 docker-7.1.0 fastapi-0.115.12 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 gunicorn-23.0.0 mlflow-2.22.0 mlflow-skinny-2.22.0 starlette-0.46.2 uvicorn-0.34.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Citi Bike Pipeline using Hopsworks Feature Store\n",
        "import pandas as pd\n",
        "import hopsworks\n",
        "from hsfs.feature import Feature\n",
        "import importlib\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "import lightgbm as lgb\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import os\n",
        "\n",
        "# ğŸ” Replace with your actual API key and project name\n",
        "API_KEY = \"O0CkvDFbriJbVIUX.y0wtVtBJ1parrzgFF0iI0phKhiH94AtVvgxjkcRN3tmK23u7iwuopQVcSzJkZqAr\"\n",
        "PROJECT_NAME = \"citibike_pred\"  # Hopsworks project name\n",
        "FEATURE_GROUP_NAME = \"cbtpsc_cleaned_v1\"  # Fresh feature group name\n",
        "INPUT_CSV = \"/content/202504-citibike-tripdata_4.csv\"  # Upload this to Colab first\n",
        "\n",
        "# DagsHub Authentication Setup\n",
        "DAGSHUB_USERNAME = \"mahiswar\"  # Replace with your DagsHub username\n",
        "DAGSHUB_REPO = \"citibike-prediction\"  # Replace with your DagsHub repository name\n",
        "DAGSHUB_TOKEN = \"d7d9f484e3a62e7008860874aeae551b77226cec\"  # Replace with your DagsHub token\n",
        "\n",
        "# Tracking URI for DagsHub MLflow\n",
        "mlflow.set_tracking_uri(f\"https://dagshub.com/{DAGSHUB_USERNAME}/{DAGSHUB_REPO}.mlflow\")\n",
        "\n",
        "# Set the authentication token in environment variables\n",
        "os.environ['MLFLOW_TRACKING_USERNAME'] = DAGSHUB_USERNAME\n",
        "os.environ['MLFLOW_TRACKING_PASSWORD'] = DAGSHUB_TOKEN\n",
        "\n",
        "# Create or use existing experiment in DagsHub\n",
        "mlflow.set_experiment(\"cbtpsc-experiments\")  # This experiment will be created in DagsHub\n",
        "\n",
        "print(\"âœ… Connected to DagsHub MLflow Tracking\")\n",
        "\n",
        "# Load data\n",
        "def load_data(file_path):\n",
        "    print(f\"ğŸ“¥ Loading data from {file_path} ...\")\n",
        "    df = pd.read_csv(\n",
        "        file_path,\n",
        "        dtype={\n",
        "            'start_station_id': str,\n",
        "            'end_station_id': str,\n",
        "            'ride_id': str,\n",
        "            'rideable_type': str,\n",
        "            'start_station_name': str,\n",
        "            'end_station_name': str,\n",
        "            'member_casual': str\n",
        "        },\n",
        "        parse_dates=['started_at', 'ended_at'],\n",
        "        low_memory=False,\n",
        "    )\n",
        "    df.columns = df.columns.str.strip()\n",
        "    print(\"âœ… Data loaded. Columns:\", df.columns.tolist())\n",
        "    return df\n",
        "\n",
        "# Select top 3 start stations\n",
        "def select_top_locations(df):\n",
        "    top3 = df['start_station_name'].value_counts().nlargest(3).index.tolist()\n",
        "    print(f\"ğŸ™ï¸ Top 3 start stations: {top3}\")\n",
        "    return top3\n",
        "\n",
        "# Preprocess data\n",
        "def clean_and_preprocess_data(df, top_locations):\n",
        "    print(\"ğŸ§¼ Preprocessing data...\")\n",
        "    df = df[df['start_station_name'].isin(top_locations)].copy()\n",
        "    df.dropna(inplace=True)\n",
        "    df['trip_duration'] = (df['ended_at'] - df['started_at']).dt.total_seconds() / 60\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "    print(\"âœ… Preprocessing complete.\")\n",
        "    return df\n",
        "\n",
        "# Save data to CSV\n",
        "def save_data_to_csv(df, output_file=\"cleaned_citi_bike_data.csv\"):\n",
        "    if df.empty:\n",
        "        print(\"âš ï¸ DataFrame is empty. Skipping save.\")\n",
        "        return\n",
        "    df.to_csv(output_file, index=False)\n",
        "    print(f\"ğŸ“ Data saved to {output_file}.\")\n",
        "\n",
        "# Store data in Hopsworks\n",
        "def store_data_in_hopsworks(df, api_key_value, project_name, feature_group_name):\n",
        "    try:\n",
        "        project = hopsworks.login(api_key_value=api_key_value, project=project_name)\n",
        "        print(f\"âœ… Logged into Hopsworks project: {project.name}\")\n",
        "        fs = project.get_feature_store()\n",
        "\n",
        "        features = [\n",
        "            Feature(\"ride_id\", \"string\"),\n",
        "            Feature(\"rideable_type\", \"string\"),\n",
        "            Feature(\"started_at\", \"timestamp\"),\n",
        "            Feature(\"ended_at\", \"timestamp\"),\n",
        "            Feature(\"start_station_name\", \"string\"),\n",
        "            Feature(\"start_station_id\", \"string\"),\n",
        "            Feature(\"end_station_name\", \"string\"),\n",
        "            Feature(\"end_station_id\", \"string\"),\n",
        "            Feature(\"start_lat\", \"double\"),\n",
        "            Feature(\"start_lng\", \"double\"),\n",
        "            Feature(\"end_lat\", \"double\"),\n",
        "            Feature(\"end_lng\", \"double\"),\n",
        "            Feature(\"member_casual\", \"string\"),\n",
        "            Feature(\"trip_duration\", \"double\"),\n",
        "        ]\n",
        "\n",
        "        # ğŸ” Always delete FG if exists (to avoid corrupt schema)\n",
        "        try:\n",
        "            fg_existing = fs.get_feature_group(name=feature_group_name, version=1)\n",
        "            if fg_existing:\n",
        "                fg_existing.delete()\n",
        "                print(f\"ğŸ§¹ Deleted existing feature group '{feature_group_name}' (version 1)\")\n",
        "        except:\n",
        "            print(f\"â„¹ï¸ No existing feature group to delete.\")\n",
        "\n",
        "        # âœ… Create new FG\n",
        "        fg = fs.create_feature_group(\n",
        "            name=feature_group_name,\n",
        "            version=1,\n",
        "            description=\"Cleaned Citi Bike data with trip duration\",\n",
        "            primary_key=[\"ride_id\"],\n",
        "            event_time=\"started_at\",\n",
        "            features=features,\n",
        "            online_enabled=True\n",
        "        )\n",
        "        print(f\"ğŸ“Š Feature group '{feature_group_name}' created.\")\n",
        "\n",
        "        # ğŸ”„ Ensure types match\n",
        "        for feat in features:\n",
        "            col = feat.name\n",
        "            if col in df.columns:\n",
        "                if feat.type == 'string':\n",
        "                    df[col] = df[col].astype(str)\n",
        "                elif feat.type == 'timestamp':\n",
        "                    df[col] = pd.to_datetime(df[col])\n",
        "                elif feat.type == 'double':\n",
        "                    df[col] = pd.to_numeric(df[col])\n",
        "\n",
        "        # ğŸš€ Insert data\n",
        "        fg.insert(df, write_options={\"wait_for_job\": True})\n",
        "        print(\"âœ… Data inserted into Feature Group successfully.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"âŒ Error inserting data into Hopsworks:\", e)\n",
        "\n",
        "# STEP 2a: Create 28-day lag features\n",
        "def create_lag_features(df, days=28):\n",
        "    print(f\"ğŸ§¼ Creating {days}-day lag features...\")\n",
        "\n",
        "    df['pickup_date'] = df['started_at'].dt.date\n",
        "    df = df.sort_values(by=['start_station_name', 'pickup_date'])\n",
        "\n",
        "    # Create lag features (shift the trip_duration for past 'days' days)\n",
        "    for i in range(1, days + 1):\n",
        "        df[f'lag_{i}'] = df.groupby('start_station_name')['trip_duration'].shift(i)\n",
        "\n",
        "    df.dropna(inplace=True)  # Drop rows with missing lag values\n",
        "    print(f\"âœ… Created {days}-day lag features.\")\n",
        "    return df\n",
        "\n",
        "# STEP 2b: Train LightGBM Model and Log in MLflow\n",
        "def log_lgbm_model(df):\n",
        "    print(\"ğŸ§‘â€ğŸ’» Training LightGBM model...\")\n",
        "\n",
        "    # Ensure lag features are created\n",
        "    df_with_lags = create_lag_features(df, days=28)\n",
        "\n",
        "    # Select features (lags)\n",
        "    feature_cols = [f'lag_{i}' for i in range(1, 29)]\n",
        "\n",
        "    X = df_with_lags[feature_cols]\n",
        "    y = df_with_lags['trip_duration']\n",
        "\n",
        "    # Split data into train/test\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train LightGBM model\n",
        "    model = lgb.LGBMRegressor()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict and calculate MAE\n",
        "    y_pred = model.predict(X_test)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    print(f\"Model MAE: {mae}\")\n",
        "\n",
        "    # Log the model and its metrics in MLflow\n",
        "    with mlflow.start_run():\n",
        "        mlflow.log_metric(\"mae_lgbm\", mae)\n",
        "        mlflow.log_param(\"model\", \"LightGBM\")\n",
        "        mlflow.sklearn.log_model(model, \"lgbm_model\")\n",
        "\n",
        "    print(\"âœ… LightGBM model logged in MLflow\")\n",
        "\n",
        "    return model, mae  # Ensure the model and mae are returned\n",
        "\n",
        "# STEP 3: Feature Reduction Model (Top 10 Features based on Importance)\n",
        "def feature_reduction_model(df, model):\n",
        "    # Get feature importance from the trained model\n",
        "    feature_importance = model.feature_importances_\n",
        "\n",
        "    # Create a DataFrame with feature names and their importance\n",
        "    feature_names = [f'lag_{i}' for i in range(1, 29)]  # 28 lag features\n",
        "    feature_importance_df = pd.DataFrame({\n",
        "        'feature': feature_names,\n",
        "        'importance': feature_importance\n",
        "    })\n",
        "\n",
        "    # Sort features by importance\n",
        "    feature_importance_df = feature_importance_df.sort_values(by='importance', ascending=False)\n",
        "\n",
        "    # Select top 10 features\n",
        "    top_10_features = feature_importance_df['feature'].head(10).tolist()\n",
        "    print(f\"âœ… Selected top 10 features: {top_10_features}\")\n",
        "\n",
        "    # STEP 3a: Train model with top 10 features\n",
        "    X = df[top_10_features]\n",
        "    y = df['trip_duration']\n",
        "\n",
        "    # Split data into train/test\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train LightGBM model\n",
        "    reduced_model = lgb.LGBMRegressor()\n",
        "    reduced_model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict and calculate MAE\n",
        "    y_pred = reduced_model.predict(X_test)\n",
        "    mae_reduced = mean_absolute_error(y_test, y_pred)\n",
        "    print(f\"Reduced Model MAE: {mae_reduced}\")\n",
        "\n",
        "    return reduced_model, mae_reduced\n",
        "\n",
        "# STEP 3b: Log Feature Reduction Model in MLflow\n",
        "def log_feature_reduction_model(df, base_model):\n",
        "    # Start MLflow run\n",
        "    with mlflow.start_run():\n",
        "        # Create lag features\n",
        "        df_with_lags = create_lag_features(df, days=28)\n",
        "\n",
        "        # Train feature reduction model and get MAE\n",
        "        reduced_model, mae_reduced = feature_reduction_model(df_with_lags, base_model)\n",
        "\n",
        "        # Log model and metrics in MLflow\n",
        "        mlflow.log_metric(\"mae_reduced\", mae_reduced)\n",
        "        mlflow.log_param(\"model\", \"LightGBM with Feature Reduction (top 10 features)\")\n",
        "        mlflow.sklearn.log_model(reduced_model, \"lgbm_model_reduced\")\n",
        "\n",
        "    print(\"âœ… Feature Reduction model logged in MLflow\")\n",
        "def log_baseline_model(df):\n",
        "    print(\"ğŸ§‘â€ğŸ’» Logging baseline model (average trip duration)...\")\n",
        "    average_duration = df['trip_duration'].mean()\n",
        "    with mlflow.start_run():\n",
        "        mlflow.log_metric(\"mae_baseline\", average_duration)  # Log as MAE for comparison\n",
        "        mlflow.log_param(\"model\", \"Baseline (Average)\")\n",
        "    print(f\"âœ… Baseline model logged. Average trip duration: {average_duration}\")\n",
        "\n",
        "# Main function to load, preprocess, log baseline, and train models\n",
        "def main():\n",
        "    # Set up MLflow experiment (important step)\n",
        "    mlflow.set_tracking_uri(f\"https://dagshub.com/mahiswar/citibike-prediction.mlflow\")\n",
        "    mlflow.set_experiment(\"cbtpsc-experiments\")\n",
        "    print(\"âœ… Connected to DagsHub MLflow Tracking\")\n",
        "\n",
        "    df = load_data(INPUT_CSV)\n",
        "    top_stations = select_top_locations(df)\n",
        "    cleaned_df = clean_and_preprocess_data(df, top_stations)\n",
        "    save_data_to_csv(cleaned_df)\n",
        "    store_data_in_hopsworks(cleaned_df, API_KEY, PROJECT_NAME, FEATURE_GROUP_NAME)\n",
        "\n",
        "    # Log Baseline model\n",
        "    log_baseline_model(cleaned_df)\n",
        "\n",
        "    # Train and log LightGBM model\n",
        "    model, mae = log_lgbm_model(cleaned_df)\n",
        "\n",
        "    # Log Feature Reduction model\n",
        "    log_feature_reduction_model(cleaned_df, model)\n",
        "\n",
        "    print(\"âœ… Pipeline finished!\")\n",
        "\n",
        "# Run everything\n",
        "main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZHL6af8aSPu",
        "outputId": "9e285b65-9a3b-4584-c57c-ed46b53539f9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Connected to DagsHub MLflow Tracking\n",
            "âœ… Connected to DagsHub MLflow Tracking\n",
            "ğŸ“¥ Loading data from /content/202504-citibike-tripdata_4.csv ...\n",
            "âœ… Data loaded. Columns: ['ride_id', 'rideable_type', 'started_at', 'ended_at', 'start_station_name', 'start_station_id', 'end_station_name', 'end_station_id', 'start_lat', 'start_lng', 'end_lat', 'end_lng', 'member_casual']\n",
            "ğŸ™ï¸ Top 3 start stations: ['W 21 St & 6 Ave', 'Pier 61 at Chelsea Piers', 'Lafayette St & E 8 St']\n",
            "ğŸ§¼ Preprocessing data...\n",
            "âœ… Preprocessing complete.\n",
            "ğŸ“ Data saved to cleaned_citi_bike_data.csv.\n",
            "Connection closed.\n",
            "\n",
            "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1228956\n",
            "âœ… Logged into Hopsworks project: citibike_pred\n",
            "ğŸ“Š Feature group 'cbtpsc_cleaned_v1' created.\n",
            "Feature Group created successfully, explore it at \n",
            "https://c.app.hopsworks.ai:443/p/1228956/fs/1213521/fg/1454510\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Uploading Dataframe: 100.00% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Rows 8106/8106 | Elapsed Time: 00:00 | Remaining Time: 00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Launching job: cbtpsc_cleaned_v1_1_offline_fg_materialization\n",
            "Job started successfully, you can follow the progress at \n",
            "https://c.app.hopsworks.ai:443/p/1228956/jobs/named/cbtpsc_cleaned_v1_1_offline_fg_materialization/executions\n",
            "âœ… Data inserted into Feature Group successfully.\n",
            "ğŸ§‘â€ğŸ’» Logging baseline model (average trip duration)...\n",
            "ğŸƒ View run defiant-bug-716 at: https://dagshub.com/mahiswar/citibike-prediction.mlflow/#/experiments/0/runs/6ab6915504b5458e87c03900caa7531b\n",
            "ğŸ§ª View experiment at: https://dagshub.com/mahiswar/citibike-prediction.mlflow/#/experiments/0\n",
            "âœ… Baseline model logged. Average trip duration: 10.92209647174932\n",
            "ğŸ§‘â€ğŸ’» Training LightGBM model...\n",
            "ğŸ§¼ Creating 28-day lag features...\n",
            "âœ… Created 28-day lag features.\n",
            "Model MAE: 6.793413212119793\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/05/09 19:56:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸƒ View run mysterious-robin-827 at: https://dagshub.com/mahiswar/citibike-prediction.mlflow/#/experiments/0/runs/2ae1b2a0c32842ddb4846dfd78b2326a\n",
            "ğŸ§ª View experiment at: https://dagshub.com/mahiswar/citibike-prediction.mlflow/#/experiments/0\n",
            "âœ… LightGBM model logged in MLflow\n",
            "ğŸ§¼ Creating 28-day lag features...\n",
            "âœ… Created 28-day lag features.\n",
            "âœ… Selected top 10 features: ['lag_6', 'lag_1', 'lag_24', 'lag_10', 'lag_18', 'lag_11', 'lag_4', 'lag_2', 'lag_5', 'lag_7']\n",
            "Reduced Model MAE: 6.74064182594568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/05/09 19:56:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸƒ View run sedate-skunk-881 at: https://dagshub.com/mahiswar/citibike-prediction.mlflow/#/experiments/0/runs/a84a4a48e99c4a0798724342f30bc2fb\n",
            "ğŸ§ª View experiment at: https://dagshub.com/mahiswar/citibike-prediction.mlflow/#/experiments/0\n",
            "âœ… Feature Reduction model logged in MLflow\n",
            "âœ… Pipeline finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "joSCzQPFaUAF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}